# -*- coding: utf-8 -*-
"""Day 8 - Customer Clustering

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P60SjswChBJ0kyTMgXpaYc_5cTfjmjk4

**Importing Libraries**
"""

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""**Importing the dataset**"""

# Importing the dataset
dataset = pd.read_csv('Customers.csv')
X = dataset.iloc[:, [3, 4]].values

dataset.head(2)

X

"""**Elbow Method - to find optimal number of clusters**  
In the Elbow method, we are actually varying the number of clusters (K) from 1 â€“ 10. For each value of K, we are calculating WCSS.  
  

**(Within-Cluster Sum of Square)**  
WCSS is the sum of the squared distance between each point and the centroid in a cluster.  
  
When we plot the WCSS with the K value, the plot looks like an Elbow.   As the number of clusters increases, the WCSS value will start to decrease. WCSS value is largest when K = 1.  
  
When we analyze the graph, we can see that the graph will rapidly change at a point and thus creating an elbow shape. From this point, the graph moves almost parallel to the X-axis. The K value corresponding to this point is the optimal value of K or an optimal number of clusters.
"""

# Using the elbow method to find the optimal number of clusters
from sklearn.cluster import KMeans
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42, n_init='auto')
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)
plt.plot(range(1, 11), wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

"""**Training the model**"""

# Training the K-Means model on the dataset
kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)
y_kmeans = kmeans.fit_predict(X)

y_kmeans.shape

X.shape

"""**Visualizing the clusters**"""

# Visualising the clusters
plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 30, c = 'red', label = 'Cluster 1')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 30, c = 'blue', label = 'Cluster 2')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 30, c = 'green', label = 'Cluster 3')
plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 30, c = 'cyan', label = 'Cluster 4')
plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 30, c = 'magenta', label = 'Cluster 5')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 25, c = 'black', label = 'Centroids')
plt.title('Clusters of customers')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
# plt.show()

